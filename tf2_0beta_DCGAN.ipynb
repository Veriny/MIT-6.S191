{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2.0beta_DCGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Veriny/MIT-6.S191/blob/master/tf2_0beta_DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDmWyG5Kr58s",
        "colab_type": "code",
        "outputId": "f05afa47-7376-4201-d07d-f0f0b3e5c450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "!pip install -q tensorflow==2.0.0-beta1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 87.9MB 1.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 41.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 33.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBBO_SGBsy8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI70pjqftPpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q imageio\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W12J3uAStTae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u21zz1botWEb",
        "colab_type": "code",
        "outputId": "6535edec-9523-4872-f297-45476f148142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(train_images, train_labels), (_,_) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViNLmvZQtkuj",
        "colab_type": "code",
        "outputId": "c743eb15-2968-425b-ef1e-69c3a91ea928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_images.shape[0])\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "\n",
        "#Make the images between -1 and 1\n",
        "train_images = (train_images - 127.5) / 127.5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0T6ZnqZuJHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWYa__2HuPDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf16trMOuSnK",
        "colab_type": "code",
        "outputId": "1ca8b442-82cd-463c-c069-ba2dbbc703d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape\n",
        "def pepegahands(mod):\n",
        "  mod.add(tf.keras.layers.BatchNormalization())\n",
        "  mod.add(tf.keras.layers.LeakyReLU())\n",
        "  \n",
        "def krappa():\n",
        "  print('pepega')  \n",
        "krappa()\n",
        "def pepega():\n",
        "  krappa()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pepega\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cNvVCwruyAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_generator():\n",
        "  model = tf.keras.Sequential()\n",
        "  #We take in 100 samples at once?\n",
        "  krappa()\n",
        "  model.add(tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape= (100,)))\n",
        "  #Now, we do batch normalization, which causes the data to become normally distributed with µ = 0 and stdev = 1. For why this is necessary: https://medium.com/deeper-learning/glossary-of-deep-learning-batch-normalisation-8266dcd2fa82\n",
        "  pepegahands(model)\n",
        "  model.add(tf.keras.layers.Reshape((7, 7, 256)))\n",
        "  assert model.output_shape == (None, 7,7,256)\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(128, (5,5), strides= (1,1), padding = 'same', use_bias = False))\n",
        "  pepegahands(model)\n",
        "  model.add(tf.keras.layers.Conv2DTranspose(64, (5,5), strides= (2,2), padding = 'same', use_bias = False))\n",
        "  pepegahands(model)\n",
        "  model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 28, 28, 1)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59A8WAISv44Q",
        "colab_type": "code",
        "outputId": "91f46627-100c-4fae-fd52-7715f4388d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "generator = create_generator()\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training = False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pepega\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WTJS89mBdLk",
        "colab_type": "code",
        "outputId": "434b2d3a-fc5d-45df-fa8f-025ea1fb2cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2ffa7114a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fi1ATo3EXUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_discriminator():\n",
        "  #sequential model with 2 Conv2D layers (w/ Leaky ReLu and 0.3 Dropout chance).\n",
        "  #At the end we will flatten into a dense layer with a single neuron.\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(128, (5,5), strides=(1,1), padding = 'same', input_shape = [28,28,1]))\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "  model.add(tf.keras.layers.Conv2D(64, (5,5), strides=(2,2), padding = 'same'))\n",
        "  model.add(tf.keras.layers.LeakyReLU())\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(1))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iipHZ188KmZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = create_discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGr5PYxaLM71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = discriminator(generated_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_kEdQZCUMGi",
        "colab_type": "code",
        "outputId": "b3eac7a5-7379-448a-ac22-80696d1e6be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(result)\n",
        "#bruh moment"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.00074392]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRIteifAUxDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGqKc2PBVpGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define discriminator loss using helper functions\n",
        "#From Tensorflow's docs: This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s.\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeroes_like(fake_output), fake_output)\n",
        "  return real_loss + fake_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqpN-NMLXAqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define generator loss\n",
        "#From Tensorflow Docs: The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, we will compare the discriminators decisions on the generated images to an array of 1s.\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O-txdcoXCe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4\n",
        "                                              )\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeGcuGuhGbPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer, dscriminator_optimizer=discriminator_optimizer,generator=generator,discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1XJa6PwISuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA53_G5dIZcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "3872fb6a-851e-4e1e-ca49-4e7f4709ed4a"
      },
      "source": [
        "#From the tensorflow wiki: The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator.\n",
        "def train_step(images):\n",
        "  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as discriminator_tape:\n",
        "    generated_images = generator(noise, training = True) "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-ccc4be24aea3>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    with tf.Gradien\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}